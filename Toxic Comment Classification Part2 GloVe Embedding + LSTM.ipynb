{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "\n",
    "## Part2: GloVe + LSTM in Keras (in progress)\n",
    "__Global Vectors (GloVe)  and Long Short Term Memory (LSTM) in Keras__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the second part of Toxic comment classification project. The first part, Part1: Tfidf + Logistic Regression, is the other notebook in this repository. To summarize Part1, I used the Tfidf vectorization to make a feature matrix and applied logistic regressions to predict each type of toxicity separately. The AUC score was .9745 and I did some error anlaysis, which showed some possible improvement.\n",
    "\n",
    "In Part2, I focus on neural network techniques. I will find word embeddings using a neural network layer and the found embeddings (vectors) will be fed to other layers including Long short term memory (LSTM) one. LSTM network is a recurrent neural network that captures long-term dependencies. It is known to be useful for natural language precessing (NLP) and successful at detecting patterns in long texts. This work is based on the short Kaggle kernel https://www.kaggle.com/jhoward/improved-lstm-baseline-glove-dropout, but I modified and extended it along with many more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import codecs, sys, os \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Input,Embedding,Bidirectional,LSTM,GlobalMaxPool1D,Dense,Dropout,Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data sets are same as before (see Part1 for more descriptions and brief EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data sets\n",
    "train = pd.read_csv('train.csv') #training set\n",
    "test = pd.read_csv('test.csv') #test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comments only\n",
    "train_comment_array = train['comment_text'].values\n",
    "test_comment_array = test['comment_text'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will use pre-trained vectors GloVe (Global vectors) downloaded from https://nlp.stanford.edu/projects/glove/ and they will be further trained using my texts in a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pre-trained word vectors, GloVe \n",
    "word_vector_file = 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several options for GloVe, but I will try to se the smallest file. 6B.50d means there are 6 billion tokens each represented as a word embedding vector of 50 dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For word embedding, I need to decide 3 numbers:\n",
    "- Vocabulary size, i.e., number of words in my vocabulary: __max_feaures__\n",
    "- Number of words in each comment: __maxlen__\n",
    "- Dimension of a word embedding vector: __word_vec_dim__\n",
    "\n",
    "They can be tuned to obtain better results. The value of word_vec_dim should be 50 since I use the above file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vec_dim =50 # dimension of Glove vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before comments are fed to my neural networks, each comment needs to be tokenized and transformed to a sequence of numbers each representing a word. I decided to make the vocabulary of size 20000 by convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000 # number of words in my vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = max_features)\n",
    "tokenizer.fit_on_texts(list(train_comment_array)+list(test_comment_array)) #input: list of texts to train on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312735"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.document_count # number of documents (train + test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most frequent 10 words: [('the', 1), ('to', 2), ('of', 3), ('a', 4), ('and', 5), ('you', 6), ('i', 7), ('is', 8), ('that', 9), ('in', 10)]\n",
      "Number of unique words: 394787\n"
     ]
    }
   ],
   "source": [
    "# Dictionary of word to index (index for this particular data)\n",
    "word_to_index = tokenizer.word_index\n",
    "print(\"The most frequent 10 words:\",list(word_to_index.items())[:10] )\n",
    "print(\"Number of unique words:\",len(word_to_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "word_to_index is the dictionary of word (key): index (value) pairs. There are 394787 unique words in my data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(list(word_to_index.values())) # index starts from 1 (not 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the index for word starts from 1, not 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('walton', 31),\n",
       " ('fragile', 31),\n",
       " (\"'new\", 31),\n",
       " ('spacex', 31),\n",
       " ('skimming', 31),\n",
       " ('riddle', 31),\n",
       " ('pag', 31),\n",
       " ('demonstrators', 31),\n",
       " ('gaa', 31),\n",
       " ('pogroms', 31)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_count = tokenizer.word_counts\n",
    "[(word, word_to_count[word]) for word,__  in list(word_to_index.items())[19990:20000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the least frequent 10 words and their frequencies in my vocabulary of size 20000. The frequencies are pretty negligible comparing to other frequent words, so 20000 seems to be not too small (also not too big to handle). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.word_docs # dictionary mapping words to the number of documents that have the words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's transform each comment to a sequence of word indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of index sequence each representing a comment\n",
    "train_comment_seq = tokenizer.texts_to_sequences(train_comment_array)\n",
    "test_comment_seq = tokenizer.texts_to_sequences(test_comment_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of words in each comment should be fixed as maxlen in order to be fed to a neural network. Comments longer than maxlen will be truncated and comments shorter than maxlen will be padded with zero. To decide maxlen, I will investigate the distribution of word counts in comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = np.vectorize(len)\n",
    "num_words = lengths(train_comment_seq)\n",
    "plt.hist(num_words, bins=50, edgecolor='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(num_words, columns=[' ']).boxplot()\n",
    "plt.ylabel('Word counts in comments')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the number of words reaches around 1400, the outliers start before 200 words and the box does not reach even 100 words. Thus, I tried both 200 and 100 for maxlen and 200 maxlen did not improve the performance much while 200 takes much longer than 100 maxlen. Therefore, I decided to use 100 for my final report, but again the number can be further tuned for better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 100 # fixed number of words in each comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truncate and pad (with zeros) to make equal size comments\n",
    "train_comment_seq_pad = pad_sequences(train_comment_seq, maxlen = maxlen, padding='post', truncating='post' )\n",
    "test_comment_seq_pad = pad_sequences(test_comment_seq, maxlen = maxlen, padding='post', truncating='post' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, padding='pre', truncating='pre' are default values. I tried the combination of padding='pre', truncating='post' (with maxlen = 200), but they gave pretty similar results.\n",
    "\n",
    "Now it is time to make the embedding matrix. The GloVe txt file has data like this 'the 0.418 0.24968 -0.41242 0.1217 ...' for the token 'the'. To separate the first item, the word 'the', from the rest, a sequence of numbers representing the word vector for 'the', I need a helper function get_word_vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_vec(word,*vec): \n",
    "    return word, np.asarray(vec, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dictionary mapping a word to its GloVe vector (encoding=\"utf8\" removed the error) \n",
    "word_to_vec = dict(get_word_vec(*item.strip().split()) for item in open(word_vector_file, encoding=\"utf8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will initialize an embedding matrix as a numpy array of shape (max_features, word_vec_dim) with random numbers from a normal distribution. The normal distribution has mean and standard deviation of word_to_vec values aggregated across all vectors. By this way of initialization, new words not among the pretrained words can have word vectors similar to those of pretrained words before being trained here. I assumed max_feaures is less than or equal to the number of unique words in texts since max_feaures = 20000 and len(word_to_index) = 394787 in my data set. The words in the embedding matrix will be ordered as in the words in word_to_index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.020940498, 0.6441043)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check mean and std of aggregated values of word_to_vec\n",
    "np.stack(word_to_vec.values()).mean(), np.stack(word_to_vec.values()).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make embedding matrix\n",
    "embed_matrix = np.random.normal(np.stack(word_to_vec.values()).mean(), \n",
    "                                np.stack(word_to_vec.values()).std(),\n",
    "                               (max_features, word_vec_dim))\n",
    "\n",
    "for word, idx in word_to_index.items():\n",
    "    if idx > max_features: # index idx starts from 1 (not 0) in word_to_index\n",
    "        break\n",
    "    vec = word_to_vec.get(word, None) # need get() to get None for the case word is not in keys\n",
    "    if vec is not None:\n",
    "        embed_matrix[idx-1] = vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Labels of training set\n",
    "labels = train[categories].values\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with Bidirectional LSTM(50)+dropout(0.1) + GlobalMaxPool1D + Dense(50 & 6)\n",
    "\n",
    "# Define comment_sequences as input of the model\n",
    "comment_sequences = Input(shape=(maxlen,))\n",
    "# Propagate comment_sequences through embedding layer and output the embeddings\n",
    "X = Embedding(max_features, word_vec_dim, weights=[embed_matrix])(comment_sequences)\n",
    "# Propagate the embeddings through Bi-LSTM layer with 50 dimensional hidden state\n",
    "# Add dropouts for both directions (rate can be tuned)\n",
    "X = Bidirectional(LSTM(50, return_sequences= True, dropout= 0.1, recurrent_dropout= 0.1))(X)\n",
    "# Apply Global max pooling for temporal data of 3D tensor and output 2D tensor without temporal dim\n",
    "X = GlobalMaxPool1D()(X)\n",
    "# Propagate X through a Dense layer to output a batch of 50 dim vectors\n",
    "X = Dense(50, activation= \"relu\")(X) \n",
    "# Add dropouts\n",
    "X = Dropout(0.1)(X) \n",
    "# Propagate X through a Dense layer to output a batch of 6 dim vectors ( 1 dim for each category)\n",
    "# Add sigmoid activation to get probability between 0 and 1 for each cateogry\n",
    "X = Dense(6, activation= \"sigmoid\")(X)\n",
    "# Create Model which converts input comment_sequences into output X\n",
    "model = Model(inputs= comment_sequences, outputs= X)\n",
    "# Compile the model with binary crossentropy loss function and adaptive momentum optimizer\n",
    "model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many tunable hyperparameters like dropout rates, activation functions, dimensions of LSTM and  dense layer, optimizers. Although we need AUC, we cannot choose AUC for metrics since AUC cannot be accumulated in mini batches. If necessary, AUC has to be computed using all data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 328s 2ms/step - loss: 0.0635 - acc: 0.9783 - val_loss: 0.0502 - val_acc: 0.9820\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 327s 2ms/step - loss: 0.0459 - acc: 0.9830 - val_loss: 0.0502 - val_acc: 0.9817\n",
      "Wall time: 10min 55s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x136939b2ba8>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(train_comment_seq_pad, labels, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 39s 257us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for test set\n",
    "prob_predictions = model.predict([test_comment_seq_pad], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission[categories]= prob_predictions #can enter multiple columns at once if columns are already there\n",
    "submission.to_csv('submission_LSTM1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only way to check performance on the test set is submitting my predictions to the leader board (LB) on Kaggle, so I prepared the submisison file and submitted.\n",
    "\n",
    "LB AUC: 0.9704 \n",
    "\n",
    "This is slighly worse than Tfidf + Logistic regression model (.9745) in Part1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I check if not training the pretrained embedding vectors (trainable= False) improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 244s 2ms/step - loss: 0.1043 - acc: 0.9692 - val_loss: 0.0895 - val_acc: 0.9727\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 240s 2ms/step - loss: 0.0779 - acc: 0.9755 - val_loss: 0.0732 - val_acc: 0.9763\n",
      "Wall time: 8min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# same as model1 except for trainable = False\n",
    "comment_sequences = Input(shape=(maxlen,))\n",
    "X = Embedding(max_features, word_vec_dim, weights=[embed_matrix], trainable= False)(comment_sequences)\n",
    "X = Bidirectional(LSTM(50, return_sequences= True, dropout= 0.1, recurrent_dropout= 0.1))(X)\n",
    "X = GlobalMaxPool1D()(X)\n",
    "X = Dense(50, activation= \"relu\")(X)\n",
    "X = Dropout(0.1)(X)\n",
    "X = Dense(6, activation= \"sigmoid\")(X)\n",
    "model = Model(inputs= comment_sequences, outputs= X)\n",
    "model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= ['accuracy'])\n",
    "\n",
    "model.fit(train_comment_seq_pad, labels, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 50s 328us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for test set\n",
    "prob_predictions = model.predict([test_comment_seq_pad], batch_size=1024, verbose=1)\n",
    "\n",
    "# submission\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission[categories]= prob_predictions #can enter multiple columns at once if columns are already there\n",
    "submission.to_csv('submission_LSTM4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: 0.9211 (\n",
    "\n",
    "This is much worse than the trainable embedding layer (Model1)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I try a different architecture that I used for another NLP project where I predicted emotion from senetences. The key differences in this model: \n",
    "\n",
    "- LSTM instead of Bidirectional LSTM\n",
    "- LSTM has the higher dimension (128) for hidden state \n",
    "- Higher dropout rates (.5)\n",
    "- Repeat the above steps twice\n",
    "- Only one necessary Dense layer with dimension 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 521s 4ms/step - loss: 0.1004 - acc: 0.9709 - val_loss: 0.0567 - val_acc: 0.9804\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 526s 4ms/step - loss: 0.0529 - acc: 0.9815 - val_loss: 0.0525 - val_acc: 0.9810\n",
      "Wall time: 17min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# not bidirectional LSTM(128)+dropout(0.5) twice \n",
    "comment_sequences = Input(shape=(maxlen,))\n",
    "X = Embedding(max_features, word_vec_dim, weights=[embed_matrix])(comment_sequences)\n",
    "X = LSTM(128, return_sequences= True)(X)\n",
    "X = Dropout(rate=.5)(X)\n",
    "X = LSTM(128, return_sequences = False)(X)\n",
    "X = Dropout(rate=.5)(X)\n",
    "X = Dense(6, activation= \"sigmoid\")(X)\n",
    "\n",
    "model = Model(inputs= comment_sequences, outputs= X)\n",
    "model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= ['accuracy'])\n",
    "\n",
    "model.fit(train_comment_seq_pad, labels, batch_size=32, epochs=2, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 95s 619us/step\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for test set\n",
    "prob_predictions = model.predict([test_comment_seq_pad], batch_size=1024, verbose=1)\n",
    "\n",
    "# submission\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission[categories]= prob_predictions #can enter multiple columns at once if columns are already there\n",
    "submission.to_csv('submission_LSTM3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: 0.9564 \n",
    "\n",
    "Unfortunately, this model is worse than model1. However, again there are many tunable hyperparameters that can improve this architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Ensemble: Logistic Regression with Tfidf & LSTM with GloVe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try a very simple ensemble model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_LR = pd.read_csv('submission.csv') #AUC=.9745 (from Part1 notebook)\n",
    "pred_LSTM = pd.read_csv('submission_LSTM1.csv') #AUC=.9704 (model1 in this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Emsemble = (pred_LR[categories].values + pred_LR[categories].values)/2\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission[categories]= pred_Emsemble #can enter multiple columns at once if columns are already there\n",
    "submission.to_csv('submission_LR_LSTM.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: 0.9744 (not better than Logistic Regression with Tfidf only) \n",
    "\n",
    "It is possible that the two model predictions are high correlated and that's why this ensemble does not perform better than the logistic regression model. Let me check the correlations for each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlation between two model predictions:\n",
      "toxic\n",
      "0.9149\n",
      "severe_toxic\n",
      "0.7793\n",
      "obscene\n",
      "0.9185\n",
      "threat\n",
      "0.2988\n",
      "insult\n",
      "0.8697\n",
      "identity_hate\n",
      "0.6699\n"
     ]
    }
   ],
   "source": [
    "# check correlation between the two model predictions\n",
    "print('Correlation between two model predictions:') \n",
    "correl = []\n",
    "for category in categories:\n",
    "    corr = np.corrcoef(pred_LR[category], pred_LSTM[category])[0,1]\n",
    "    correl.append(corr)\n",
    "    print(category)\n",
    "    print(\"%0.4f\"%corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation coefficients between two model predictions are pretty high except for threat (less than .3). In particular, the correlations for each of toxic, obsecene, and insult are very high (over .85). This remids me of that I tuned the hyperparameters for the logistic regression model for each category. There I found less regularization is required for more unbalanced categories. The above correlations seem to correlated with the level of imbalances. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09584448, 0.00999555, 0.05294822, 0.00299553, 0.04936361,\n",
       "       0.00880486])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# proportions of toxic comments for each category\n",
    "positive_rate = labels.mean(axis=0)\n",
    "positive_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SpearmanrResult(correlation=0.942857142857143, pvalue=0.004804664723032055)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rank order correlation between two model correlations and proportions of toxic comments\n",
    "import scipy.stats as stats\n",
    "stats.spearmanr(correl, positive_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This high correlation could be from poor performances of LSTM for some categories. Thus, I will now check performances of the LSTM model separately for each category. Then, I will apply different levels of regularization or even different architectures for different categories to improve the overall performance.\n",
    "\n",
    "First, I will fit the model for each category to see if this improves the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Fitting for toxic ###\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 342s 2ms/step - loss: 0.1509 - acc: 0.9480 - val_loss: 0.1057 - val_acc: 0.9615\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 337s 2ms/step - loss: 0.0937 - acc: 0.9651 - val_loss: 0.0987 - val_acc: 0.9641\n",
      "153164/153164 [==============================] - 54s 351us/step\n",
      "### Fitting for severe_toxic ###\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 341s 2ms/step - loss: 0.0318 - acc: 0.9900 - val_loss: 0.0217 - val_acc: 0.9910\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 337s 2ms/step - loss: 0.0216 - acc: 0.9909 - val_loss: 0.0208 - val_acc: 0.9914\n",
      "153164/153164 [==============================] - 54s 354us/step\n",
      "### Fitting for obscene ###\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 344s 2ms/step - loss: 0.0873 - acc: 0.9727 - val_loss: 0.0628 - val_acc: 0.9796\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 342s 2ms/step - loss: 0.0486 - acc: 0.9820 - val_loss: 0.0556 - val_acc: 0.9799\n",
      "153164/153164 [==============================] - 57s 372us/step\n",
      "### Fitting for threat ###\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 351s 2ms/step - loss: 0.0159 - acc: 0.9970 - val_loss: 0.0097 - val_acc: 0.9969\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 344s 2ms/step - loss: 0.0079 - acc: 0.9973 - val_loss: 0.0084 - val_acc: 0.9969\n",
      "153164/153164 [==============================] - 58s 381us/step\n",
      "### Fitting for insult ###\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 348s 2ms/step - loss: 0.0959 - acc: 0.9678 - val_loss: 0.0716 - val_acc: 0.9726\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 341s 2ms/step - loss: 0.0614 - acc: 0.9759 - val_loss: 0.0686 - val_acc: 0.9723\n",
      "153164/153164 [==============================] - 61s 401us/step\n",
      "### Fitting for identity_hate ###\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 353s 2ms/step - loss: 0.0360 - acc: 0.9912 - val_loss: 0.0263 - val_acc: 0.9914\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 342s 2ms/step - loss: 0.0210 - acc: 0.9927 - val_loss: 0.0268 - val_acc: 0.9920\n",
      "153164/153164 [==============================] - 61s 396us/step\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "for category in categories:\n",
    "    comment_sequences = Input(shape=(maxlen,))\n",
    "    X = Embedding(max_features, word_vec_dim, weights=[embed_matrix])(comment_sequences)\n",
    "    X = Bidirectional(LSTM(50, return_sequences= True, dropout= 0.1, recurrent_dropout= 0.1))(X)\n",
    "    X = GlobalMaxPool1D()(X)\n",
    "    X = Dense(50, activation= \"relu\")(X)\n",
    "    X = Dropout(0.1)(X)\n",
    "    X = Dense(1, activation= \"sigmoid\")(X)\n",
    "    model = Model(inputs= comment_sequences, outputs= X)\n",
    "    model.compile(loss= 'binary_crossentropy', optimizer= 'adam', metrics= ['accuracy'])  \n",
    "    print(\"### Fitting for {} ###\".format(category))\n",
    "    model.fit(train_comment_seq_pad, train[category], batch_size=32, epochs=2, validation_split=0.1)\n",
    "    submission[category] = model.predict([test_comment_seq_pad], batch_size=1024, verbose=1)\n",
    "    \n",
    "submission.to_csv('submission_LSTM5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: .9755\n",
    "\n",
    "This is better than all of the previous models I tried including LSTM model1 above and logistic regression model in Part1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9938879274682488"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if auc for the last category identity hate is also that high\n",
    "from sklearn import metrics\n",
    "pred = model.predict([train_comment_seq_pad], batch_size=1024, verbose=1) #for identity hate\n",
    "y = train['identity_hate']\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, pred, pos_label=1)\n",
    "metrics.auc(fpr, tpr)\n",
    "# Yes, AUC is very high just like accuracy for identity hate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems the Glove+LSMT model is especially better than Tfidf+LR model for more severely unbalanced categories (accuracy > .99). Thus, I will use the predictions by Tfidf+LR for toxic, obscene, and insult categories and predictions by GloVe+LSMT for severe toxic, threat, and identity hate categories and see if this combined prediction improves AUC. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_LR = pd.read_csv('submission.csv') #AUC=.9745 (from Part1 notebook)\n",
    "pred_LSTM = pd.read_csv('submission_LSTM5.csv') #AUC=.9755 \n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "submission['toxic']= pred_LR['toxic']\n",
    "submission['severe_toxic']= pred_LSTM['severe_toxic']\n",
    "submission['obscene']= pred_LR['obscene']\n",
    "submission['threat']= pred_LSTM['threat']\n",
    "submission['insult']= pred_LR['insult']\n",
    "submission['identity_hate']= pred_LSTM['identity_hate']\n",
    "\n",
    "submission.to_csv('submission_LR_LSTM_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: 0.9751 (not better than LSTM only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will try the simple ensemble model I tried above since the LSTM model was improved by fitting each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_Emsemble = (pred_LR[categories].values + pred_LR[categories].values)/2\n",
    "\n",
    "submission = pd.read_csv('sample_submission.csv')\n",
    "submission[categories]= pred_Emsemble #can enter multiple columns at once if columns are already there\n",
    "submission.to_csv('submission_LR_LSTM_5.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: 0.9744 (not better than LSTM only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categories severe toxic, threat, and identity hate are also those with lower correlations between the two models, so the simple ensemble model might work only for those categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "submission['toxic']= pred_LR['toxic']\n",
    "submission['severe_toxic']= (pred_LR['severe_toxic']+pred_LSTM['severe_toxic'])/2\n",
    "submission['obscene']= pred_LR['obscene']\n",
    "submission['threat']= (pred_LR['threat']+pred_LSTM['threat'])/2\n",
    "submission['insult']= pred_LR['insult']\n",
    "submission['identity_hate']= (pred_LR['identity_hate']+pred_LSTM['identity_hate'])/2\n",
    "\n",
    "submission.to_csv('submission_LR_LSTM_4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LB AUC: 0.9770 \n",
    "\n",
    "Yes! This is the best AUC I've ever got."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary so far\n",
    "\n",
    "- Made predictions using GloVe word embedding + LSTM in Keras. \n",
    "- Used multi-task learning for multiple lables (1 by 6 vector label) as mentioned in the future directions of Part1\n",
    "- LSTM models with multi-task learning was worse than the Tfidf + Logistic regression model\n",
    "- Fitting each category for the LSTM model was much slower, but made better predictions than the logistic regression\n",
    "- Found a simple ensemble method (the last one) can increase AUC even further"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
