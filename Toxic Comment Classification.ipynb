{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Toxic Comment Classification\n",
    "\n",
    "### Text Classification Project by _Hye Joo Han_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of this project\n",
    "1. <a href='#Section1'>Data Description</a>\n",
    "2. <a href='#Section2'>Project Goal</a>\n",
    "3. <a href='#Section3'>Brief EDA</a>\n",
    "4. <a href='#Section4'>Cleaning and Stemming</a>\n",
    "5. <a href='#Section5'>TfidfVectorizer</a>\n",
    "6. <a href='#Section6'>Logistic Regression</a>\n",
    "7. <a href='#Section7'>More tuning</a>\n",
    "8. <a href='#Section8'>Summary so far</a>\n",
    "9. <a href='#Section9'>Furture Directions</a>\n",
    " \n",
    "_Please note that this project has not been completed, but there is <a href='#Section8'>Summary so far</a> at the end of notebook._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'Section1'></a>\n",
    "## 1. Data Description\n",
    "- Data sets train.csv and test.csv were downloaded from a Kaggle Competition (by Jigsaw and Google) https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge \n",
    "- train.csv is the training set that contains comments with their id and 6 binary labels. \n",
    "- test.csv is the test set that contains comments and their id only. I have to predict the labels, toxicity probabilities.\n",
    "- The training set includes 8 columns: \n",
    "   - id (comment id number)\n",
    "   - comment_text (Wikipedia comments. Each comment was labeled by human raters for  6 types of toxic behaviors. The following 6 columns are the rated labels) \n",
    "   - toxic\n",
    "   - severe_toxic\n",
    "   - obscene \n",
    "   - threat\n",
    "   - insult\n",
    "   - identity_hate \n",
    "- Note that the 6 categories are not mutually exclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'Section2'></a>\n",
    "## 2. Project Goal\n",
    "Find an algorithm or create a model that predicts a probability of each type of toxicity for each comment the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'Section3'></a>\n",
    "## 3. Brief EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do some brief exploratory data analysis using the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv') #training set\n",
    "test = pd.read_csv('test.csv') #test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      "id               159571 non-null object\n",
      "comment_text     159571 non-null object\n",
      "toxic            159571 non-null int64\n",
      "severe_toxic     159571 non-null int64\n",
      "obscene          159571 non-null int64\n",
      "threat           159571 non-null int64\n",
      "insult           159571 non-null int64\n",
      "identity_hate    159571 non-null int64\n",
      "dtypes: int64(6), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>00031b1e95af7921</td>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>00037261f536c51d</td>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>00040093b2687caa</td>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "6  0002bcb3da6cb337       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "7  00031b1e95af7921  Your vandalism to the Matt Shirvington article...      0   \n",
       "8  00037261f536c51d  Sorry if the word 'nonsense' was offensive to ...      0   \n",
       "9  00040093b2687caa  alignment on this subject and which are contra...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  \n",
       "6             1        1       0       1              0  \n",
       "7             0        0       0       0              0  \n",
       "8             0        0       0       0              0  \n",
       "9             0        0       0       0              0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count shows there are _159,571_ comments. The mean shows the proportions of toxic comments for each category:\n",
    "  - Toxic:         9.58% \n",
    "  - Severe Toxic:  1.00%\n",
    "  - Obcene:        5.29%\n",
    "  - Threat:        0.30%\n",
    "  - Insult:        4.94%\n",
    "  - Identity hate: 0.88%\n",
    "  \n",
    "The proportions show this data set has very unblanced classes for each category of toxic behavior. Some of the categories like Threat (.30%), Indentity hate (.88%), and Severe Toxic (1.00%) are severely unbalanced. Thus, the validation methods such as train/test split or performance metrics should be carefully selected.\n",
    "\n",
    "There seems to be no missing values. I will confirmed this in the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id               0\n",
       "comment_text     0\n",
       "toxic            0\n",
       "severe_toxic     0\n",
       "obscene          0\n",
       "threat           0\n",
       "insult           0\n",
       "identity_hate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of comments with only white spaces\n",
    "empty_comment = 0 \n",
    "for comment in train['comment_text']:\n",
    "    if re.match('\\s+', comment):\n",
    "        empty_comment +=1\n",
    "empty_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also checked if there is any blank comment, but I found none."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample comment 0 \n",
      " Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "Sample comment 1 \n",
      " D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Sample comment 2 \n",
      " Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n"
     ]
    }
   ],
   "source": [
    "# Check some real comments\n",
    "for i in range(3):\n",
    "    print(\"Sample comment {}\".format(i),'\\n', train['comment_text'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems there are sometimes IP addresses or dates and times. CLeaning them might improve my predictions, but I will keep them there for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the length of each comment\n",
    "lengths = np.vectorize(len)\n",
    "text_len = lengths(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(text_len, bins = 50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum text length:  6 characters\n",
      "Maximum text length:  5000 characters\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum text length: \", min(text_len), \"characters\")\n",
    "print(\"Maximum text length: \", max(text_len), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comment length ranges from 6 to 5000 characters and its distribution is highly right-skewed. I wonder whether comment lengths are related to the probability of toxicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check outliers? Try a box plot and check the longest comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section4'></a>\n",
    "## 4. Cleaning and Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I will clean text comments and apply stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pandas series out of data frames \n",
    "train_comment = train['comment_text']\n",
    "test_comment = test['comment_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out with one comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To develope each step, I will first use only one comment and then apply all steps to all comments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n"
     ]
    }
   ],
   "source": [
    "sample_comment = train['comment_text'][0]\n",
    "print(sample_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted They werent vandalisms just closure on some GAs after I voted at New York Dolls FAC And please dont remove the template from the talk page since Im retired now892053827\n"
     ]
    }
   ],
   "source": [
    "# remove punctuations\n",
    "sample_comment = re.sub(r'[^\\w\\s]','',sample_comment)\n",
    "print(sample_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Explanation', 'Why', 'the', 'edits', 'made', 'under', 'my', 'username', 'Hardcore', 'Metallica', 'Fan', 'were', 'reverted', 'They', 'werent', 'vandalisms', 'just', 'closure', 'on', 'some', 'GAs', 'after', 'I', 'voted', 'at', 'New', 'York', 'Dolls', 'FAC', 'And', 'please', 'dont', 'remove', 'the', 'template', 'from', 'the', 'talk', 'page', 'since', 'Im', 'retired', 'now892053827']\n"
     ]
    }
   ],
   "source": [
    "# split text into words\n",
    "word_list = sample_comment.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "explan whi the edit made under my usernam hardcor metallica fan were revert they werent vandal just closur on some gas after i vote at new york doll fac and pleas dont remov the templat from the talk page sinc im retir now892053827 \n"
     ]
    }
   ],
   "source": [
    "# apply stemmer and combine them again\n",
    "stemmer= SnowballStemmer(\"english\")\n",
    "\n",
    "words = \"\"\n",
    "for word in word_list:\n",
    "    if word != \"\":\n",
    "        word_stemmed = stemmer.stem(word)\n",
    "        words += word_stemmed + \" \"\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply all steps to every comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it' time to apply the above steps to every comment in the training set. First, I will make a function that combines all the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    #remove punctuations\n",
    "    text_string = re.sub(r'[^\\w\\s]','',text)\n",
    "    #split text into words\n",
    "    word_list = text_string.split()\n",
    "    #apply stemmer and combine them again\n",
    "    stemmer= SnowballStemmer(\"english\")\n",
    "    words = \"\"\n",
    "    for word in word_list:\n",
    "        if word != \"\":\n",
    "            word_stemmed = stemmer.stem(word)\n",
    "            words += word_stemmed + \" \"\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original text: \n",
      " Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "\n",
      "Processed text: \n",
      " explan whi the edit made under my usernam hardcor metallica fan were revert they werent vandal just closur on some gas after i vote at new york doll fac and pleas dont remov the templat from the talk page sinc im retir now892053827 \n"
     ]
    }
   ],
   "source": [
    "print(\"Original text:\",\"\\n\", train['comment_text'][0])\n",
    "print()\n",
    "print(\"Processed text:\",\"\\n\", text_preprocessing( train['comment_text'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! The function works well for one text. Now it's time to apply the preprocessing function to all comments in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Explanation\\nWhy the edits made under my usern...\n",
       "1    D'aww! He matches this background colour I'm s...\n",
       "2    Hey man, I'm really not trying to edit war. It...\n",
       "3    \"\\nMore\\nI can't make any real suggestions on ...\n",
       "4    You, sir, are my hero. Any chance you remember...\n",
       "5    \"\\n\\nCongratulations from me as well, use the ...\n",
       "6         COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
       "7    Your vandalism to the Matt Shirvington article...\n",
       "8    Sorry if the word 'nonsense' was offensive to ...\n",
       "9    alignment on this subject and which are contra...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check original comments in the training set\n",
    "train_comment.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# stemming all comments in the training set\n",
    "train_comment_stemmed = train_comment.apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    explan whi the edit made under my usernam hard...\n",
       "1    daww he match this background colour im seem s...\n",
       "2    hey man im realli not tri to edit war it just ...\n",
       "3    more i cant make ani real suggest on improv i ...\n",
       "4    you sir are my hero ani chanc you rememb what ...\n",
       "5    congratul from me as well use the tool well talk \n",
       "6           cocksuck befor you piss around on my work \n",
       "7    your vandal to the matt shirvington articl has...\n",
       "8    sorri if the word nonsens was offens to you an...\n",
       "9    align on this subject and which are contrari t...\n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comment_stemmed.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The texts in the test set should be also stemmed since words in the test set should be vectorized and transformed into a feature matrix as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 1s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# stemming all comments in the test set\n",
    "test_comment_stemmed = test_comment.apply(text_preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    yo bitch ja rule is more succes then youll eve...\n",
       "1              from rfc the titl is fine as it is imo \n",
       "2                         sourc zaw ashton on lapland \n",
       "3    if you have a look back at the sourc the infor...\n",
       "4                    i dont anonym edit articl at all \n",
       "Name: comment_text, dtype: object"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_comment_stemmed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Done with cleaning and stemming! Now let's move on to the vectorization part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section5'></a>\n",
    "## 5. TfidfVectorizer\n",
    "A vectorizer converts a collection of text documents into a numerical (sparse) matrix with 1 row per document and 1 column per token (e.g. word). I will use the Tf-idf (term frequency inverse document frequency) vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Using stemmed comments\n",
    "vectorizer = TfidfVectorizer(analyzer ='word', \n",
    "                             stop_words='english',\n",
    "                             sublinear_tf=True, #term-freq scaling\n",
    "                             strip_accents='unicode', #works generally\n",
    "                             token_pattern=r'\\w{1,}', #1+ char words\n",
    "                             ngram_range=(1,1),\n",
    "                             max_features=10000) #consider top 10000\n",
    "\n",
    "vectorizer.fit(pd.concat([train_comment_stemmed,test_comment_stemmed]))\n",
    "\n",
    "train_feature_matrix = vectorizer.transform(train_comment_stemmed)\n",
    "#test_feature_matrix = vectorizer.transform(test_comment_stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'token_pattern' and 'ngram_range' will be tuned later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will help checking the results at glance\n",
    "def print_results():\n",
    "    print(\"### Tuning hyper-parameters for {} ###\".format(category))\n",
    "    print()\n",
    "    print(\"Best hyper-parameters on development set:\")\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid search scores on development set:\")\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.4f (+/-%0.04f) for %r\" % (mean, std * 2, params))\n",
    "    print()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Section6'></a>\n",
    "## 6. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression will be test as a classifier. I will tune some hyper-parameters, but more fine tuning will be done in the next section.\n",
    "\n",
    "#### Performance measure\n",
    "The performance measure selected is 'roc_auc' since the Kaggle competition uses the metric for evaluation. I do not believe AUC is a good measure for data with highky unbalanced classes, but the only way to evaluate my model using the test set is submitting my predictions to the leaderboard, which will let me know only AUC values. Note that high AUC scores (e.g., 0.98) from unbalanced data do not mean your model is actually predicting well. F1 or other scores could be still very bad!!! For this reason, I will check some other performance measures as well.   \n",
    "\n",
    "#### C\n",
    "The hyper-parameter 'C' for LogisticRegression represents the inverse of regularization strength. I will use \"coarse to fine\" strategy to tune C and optimize C value for each type of toxicity.\n",
    "\n",
    "#### Solver\n",
    "If 'C'=100 is included in the hyper-parameter set, 'sag' gives bunch of convergence warnings, takes so much longer and the score for 'C'=100 was worse than lower C. Thus, I omitted 100 from the 'C' range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat',\n",
       "       'insult', 'identity_hate'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns # just to coveniently copy and paste category names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories =['toxic', 'severe_toxic', 'obscene', \n",
    "             'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Tuning hyper-parameters for toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1, 'solver': 'sag'}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9595 (+/-0.0048) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.9596 (+/-0.0048) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.9696 (+/-0.0028) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.9696 (+/-0.0028) for {'C': 1, 'solver': 'sag'}\n",
      "0.9656 (+/-0.0022) for {'C': 10, 'solver': 'liblinear'}\n",
      "0.9656 (+/-0.0022) for {'C': 10, 'solver': 'sag'}\n",
      "\n",
      "### Tuning hyper-parameters for severe_toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1, 'solver': 'sag'}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9837 (+/-0.0029) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.9839 (+/-0.0025) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.9851 (+/-0.0033) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.9851 (+/-0.0032) for {'C': 1, 'solver': 'sag'}\n",
      "0.9790 (+/-0.0049) for {'C': 10, 'solver': 'liblinear'}\n",
      "0.9790 (+/-0.0049) for {'C': 10, 'solver': 'sag'}\n",
      "\n",
      "### Tuning hyper-parameters for obscene ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1, 'solver': 'sag'}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9795 (+/-0.0037) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.9797 (+/-0.0038) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.9843 (+/-0.0032) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.9843 (+/-0.0032) for {'C': 1, 'solver': 'sag'}\n",
      "0.9797 (+/-0.0026) for {'C': 10, 'solver': 'liblinear'}\n",
      "0.9797 (+/-0.0026) for {'C': 10, 'solver': 'sag'}\n",
      "\n",
      "### Tuning hyper-parameters for threat ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1, 'solver': 'liblinear'}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9739 (+/-0.0043) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.9751 (+/-0.0032) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.9830 (+/-0.0038) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.9830 (+/-0.0038) for {'C': 1, 'solver': 'sag'}\n",
      "0.9809 (+/-0.0053) for {'C': 10, 'solver': 'liblinear'}\n",
      "0.9809 (+/-0.0053) for {'C': 10, 'solver': 'sag'}\n",
      "\n",
      "### Tuning hyper-parameters for insult ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1, 'solver': 'sag'}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9707 (+/-0.0016) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.9708 (+/-0.0016) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.9756 (+/-0.0005) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.9756 (+/-0.0005) for {'C': 1, 'solver': 'sag'}\n",
      "0.9685 (+/-0.0006) for {'C': 10, 'solver': 'liblinear'}\n",
      "0.9685 (+/-0.0007) for {'C': 10, 'solver': 'sag'}\n",
      "\n",
      "### Tuning hyper-parameters for identity_hate ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1, 'solver': 'sag'}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9686 (+/-0.0043) for {'C': 0.1, 'solver': 'liblinear'}\n",
      "0.9692 (+/-0.0038) for {'C': 0.1, 'solver': 'sag'}\n",
      "0.9753 (+/-0.0033) for {'C': 1, 'solver': 'liblinear'}\n",
      "0.9753 (+/-0.0032) for {'C': 1, 'solver': 'sag'}\n",
      "0.9690 (+/-0.0032) for {'C': 10, 'solver': 'liblinear'}\n",
      "0.9690 (+/-0.0032) for {'C': 10, 'solver': 'sag'}\n",
      "\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    parameters = {'solver':['liblinear', 'sag'],'C': [.1,1,10]}\n",
    "    log_reg = LogisticRegression()   \n",
    "    clf= GridSearchCV(log_reg, parameters, scoring='roc_auc', cv=3)\n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that 1 is the best inverse regularization level 'C' among .1, 1, and 10, but the more fine turning for C will be performed in the next section.   \n",
    "\n",
    "The 'sag' solver performs slighly better than 'liblinear' except for Threat category. Since the difference between the two solvers for Threat is less than .0001 (when C is optimized), I will just use 'sag' for all categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Section7\"></a>\n",
    "## 7. More Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will fist do some tuning for C. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Tuning hyper-parameters for toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 2}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9640 (+/-0.0041) for {'C': 0.2}\n",
      "0.9681 (+/-0.0033) for {'C': 0.5}\n",
      "0.9696 (+/-0.0028) for {'C': 1}\n",
      "0.9698 (+/-0.0025) for {'C': 2}\n",
      "0.9682 (+/-0.0022) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for severe_toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 0.5}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9846 (+/-0.0026) for {'C': 0.2}\n",
      "0.9852 (+/-0.0028) for {'C': 0.5}\n",
      "0.9851 (+/-0.0032) for {'C': 1}\n",
      "0.9844 (+/-0.0037) for {'C': 2}\n",
      "0.9821 (+/-0.0044) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for obscene ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9818 (+/-0.0037) for {'C': 0.2}\n",
      "0.9836 (+/-0.0034) for {'C': 0.5}\n",
      "0.9843 (+/-0.0032) for {'C': 1}\n",
      "0.9841 (+/-0.0031) for {'C': 2}\n",
      "0.9823 (+/-0.0028) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for threat ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 2}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9771 (+/-0.0028) for {'C': 0.2}\n",
      "0.9807 (+/-0.0030) for {'C': 0.5}\n",
      "0.9830 (+/-0.0038) for {'C': 1}\n",
      "0.9840 (+/-0.0043) for {'C': 2}\n",
      "0.9832 (+/-0.0048) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for insult ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9731 (+/-0.0012) for {'C': 0.2}\n",
      "0.9751 (+/-0.0008) for {'C': 0.5}\n",
      "0.9756 (+/-0.0005) for {'C': 1}\n",
      "0.9751 (+/-0.0003) for {'C': 2}\n",
      "0.9723 (+/-0.0004) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for identity_hate ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9719 (+/-0.0034) for {'C': 0.2}\n",
      "0.9745 (+/-0.0032) for {'C': 0.5}\n",
      "0.9753 (+/-0.0032) for {'C': 1}\n",
      "0.9751 (+/-0.0033) for {'C': 2}\n",
      "0.9727 (+/-0.0034) for {'C': 5}\n",
      "\n",
      "Wall time: 3min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    parameters = {'C': [.2, .5, 1, 2, 5]}\n",
    "    log_reg = LogisticRegression(solver = 'sag')   \n",
    "    clf= GridSearchCV(log_reg, parameters, scoring='roc_auc', cv=3)\n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found the better opimized C for each category, but C will be tuned even more after finding the best vectorizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning parameters for vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the previous vectorizer, I used token_pattern=r'\\w{1,}' to consider 1+ alphanumeric character words as a token and ngram_range=(1,1). In this section, I will try token_pattern=r'\\w{2,}' to consider 2+ alphanumeric character words as a token and ngram_range=(1,2) to consider bigrams together with unigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try ngram_range=(1,2) instead of (1,1) to take bigrams into account\n",
    "vectorizer = TfidfVectorizer(analyzer ='word', \n",
    "                             stop_words='english',\n",
    "                             sublinear_tf=True, #term-freq scaling\n",
    "                             strip_accents='unicode', #works generally\n",
    "                             token_pattern=r'\\w{1,}', #1+ char words\n",
    "                             ngram_range=(1,2),\n",
    "                             max_features=10000) #consider top 10000\n",
    "vectorizer.fit(pd.concat([train_comment_stemmed,test_comment_stemmed]))\n",
    "train_feature_matrix = vectorizer.transform(train_comment_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Tuning hyper-parameters for toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9631 (+/-0.0044) for {'C': 0.2}\n",
      "0.9669 (+/-0.0036) for {'C': 0.5}\n",
      "0.9681 (+/-0.0031) for {'C': 1}\n",
      "0.9679 (+/-0.0028) for {'C': 2}\n",
      "0.9654 (+/-0.0027) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for severe_toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 0.5}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9840 (+/-0.0031) for {'C': 0.2}\n",
      "0.9845 (+/-0.0035) for {'C': 0.5}\n",
      "0.9843 (+/-0.0040) for {'C': 1}\n",
      "0.9834 (+/-0.0047) for {'C': 2}\n",
      "0.9807 (+/-0.0057) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for obscene ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9813 (+/-0.0036) for {'C': 0.2}\n",
      "0.9831 (+/-0.0034) for {'C': 0.5}\n",
      "0.9835 (+/-0.0032) for {'C': 1}\n",
      "0.9831 (+/-0.0031) for {'C': 2}\n",
      "0.9807 (+/-0.0027) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for threat ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 2}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9778 (+/-0.0023) for {'C': 0.2}\n",
      "0.9808 (+/-0.0019) for {'C': 0.5}\n",
      "0.9828 (+/-0.0023) for {'C': 1}\n",
      "0.9838 (+/-0.0026) for {'C': 2}\n",
      "0.9829 (+/-0.0029) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for insult ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9725 (+/-0.0018) for {'C': 0.2}\n",
      "0.9743 (+/-0.0014) for {'C': 0.5}\n",
      "0.9746 (+/-0.0012) for {'C': 1}\n",
      "0.9737 (+/-0.0011) for {'C': 2}\n",
      "0.9703 (+/-0.0012) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for identity_hate ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9718 (+/-0.0038) for {'C': 0.2}\n",
      "0.9742 (+/-0.0037) for {'C': 0.5}\n",
      "0.9749 (+/-0.0035) for {'C': 1}\n",
      "0.9746 (+/-0.0034) for {'C': 2}\n",
      "0.9719 (+/-0.0031) for {'C': 5}\n",
      "\n",
      "Wall time: 3min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    parameters = {'C':  [.2, .5, 1, 2, 5]}\n",
    "    log_reg = LogisticRegression(solver = 'sag')   \n",
    "    clf= GridSearchCV(log_reg, parameters, scoring='roc_auc', cv=3)\n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering bigrams made the performance worse. Now I will try the different token_pattern while keeping ngram_range=(1,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Tuning hyper-parameters for toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 2}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9637 (+/-0.0042) for {'C': 0.2}\n",
      "0.9677 (+/-0.0034) for {'C': 0.5}\n",
      "0.9692 (+/-0.0028) for {'C': 1}\n",
      "0.9695 (+/-0.0025) for {'C': 2}\n",
      "0.9678 (+/-0.0022) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for severe_toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 0.5}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9843 (+/-0.0023) for {'C': 0.2}\n",
      "0.9847 (+/-0.0024) for {'C': 0.5}\n",
      "0.9845 (+/-0.0027) for {'C': 1}\n",
      "0.9836 (+/-0.0032) for {'C': 2}\n",
      "0.9811 (+/-0.0037) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for obscene ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9814 (+/-0.0038) for {'C': 0.2}\n",
      "0.9832 (+/-0.0036) for {'C': 0.5}\n",
      "0.9838 (+/-0.0034) for {'C': 1}\n",
      "0.9836 (+/-0.0032) for {'C': 2}\n",
      "0.9817 (+/-0.0030) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for threat ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 2}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9775 (+/-0.0027) for {'C': 0.2}\n",
      "0.9811 (+/-0.0028) for {'C': 0.5}\n",
      "0.9833 (+/-0.0035) for {'C': 1}\n",
      "0.9843 (+/-0.0040) for {'C': 2}\n",
      "0.9834 (+/-0.0045) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for insult ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9729 (+/-0.0012) for {'C': 0.2}\n",
      "0.9748 (+/-0.0007) for {'C': 0.5}\n",
      "0.9753 (+/-0.0004) for {'C': 1}\n",
      "0.9747 (+/-0.0002) for {'C': 2}\n",
      "0.9720 (+/-0.0006) for {'C': 5}\n",
      "\n",
      "### Tuning hyper-parameters for identity_hate ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9710 (+/-0.0028) for {'C': 0.2}\n",
      "0.9735 (+/-0.0027) for {'C': 0.5}\n",
      "0.9743 (+/-0.0028) for {'C': 1}\n",
      "0.9740 (+/-0.0029) for {'C': 2}\n",
      "0.9716 (+/-0.0029) for {'C': 5}\n",
      "\n",
      "Wall time: 4min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#try token_pattern=r'\\w{2,}' instead of r'\\w{1,}'\n",
    "vectorizer = TfidfVectorizer(analyzer ='word', \n",
    "                             stop_words='english',\n",
    "                             sublinear_tf=True, #term-freq scaling\n",
    "                             strip_accents='unicode', #works generally\n",
    "                             token_pattern=r'\\w{2,}', #2+ char words\n",
    "                             ngram_range=(1,1),\n",
    "                             max_features=10000) #consider top 10000\n",
    "vectorizer.fit(pd.concat([train_comment_stemmed,test_comment_stemmed]))\n",
    "train_feature_matrix = vectorizer.transform(train_comment_stemmed)\n",
    "\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    parameters = {'C': [.2, .5, 1, 2, 5]}\n",
    "    log_reg = LogisticRegression(solver = 'sag')   \n",
    "    clf= GridSearchCV(log_reg, parameters, scoring='roc_auc', cv=3)\n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing token_pattern to 2+ alphanumeric charaters also made predictions worse. I expect taht changing both taken_pattern and ngram_range would not imrove the performance, I will keep the original parameters used in the previous section.\n",
    "\n",
    "I am done with tuning the vectorizer, so I will go back to tuning C for LogisticRegression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning for C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(analyzer ='word', \n",
    "                             stop_words='english',\n",
    "                             sublinear_tf=True, #term-freq scaling\n",
    "                             strip_accents='unicode', #works generally\n",
    "                             token_pattern=r'\\w{1,}', #1+ char words\n",
    "                             ngram_range=(1,1),\n",
    "                             max_features=10000) #consider top 10000\n",
    "\n",
    "vectorizer.fit(pd.concat([train_comment_stemmed,test_comment_stemmed]))\n",
    "\n",
    "train_feature_matrix = vectorizer.transform(train_comment_stemmed)\n",
    "test_feature_matrix = vectorizer.transform(test_comment_stemmed) # finally we need this line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized C in the previous section was 2, .5, 1, 2, 1, 1 for 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', respectively. Thus, I will do fine tuning around the best C of each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Tuning hyper-parameters for toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1.4}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9713 (+/-0.0117) for {'C': 1.1}\n",
      "0.9713 (+/-0.0117) for {'C': 1.2}\n",
      "0.9714 (+/-0.0116) for {'C': 1.3}\n",
      "0.9714 (+/-0.0116) for {'C': 1.4}\n",
      "0.9714 (+/-0.0116) for {'C': 1.5}\n",
      "0.9714 (+/-0.0116) for {'C': 1.6}\n",
      "0.9713 (+/-0.0116) for {'C': 1.7}\n",
      "0.9713 (+/-0.0116) for {'C': 1.8}\n",
      "0.9713 (+/-0.0116) for {'C': 1.9}\n",
      "0.9712 (+/-0.0116) for {'C': 2.0}\n",
      "0.9712 (+/-0.0116) for {'C': 2.1}\n",
      "0.9712 (+/-0.0116) for {'C': 2.2}\n",
      "0.9711 (+/-0.0116) for {'C': 2.3}\n",
      "0.9711 (+/-0.0116) for {'C': 2.4}\n",
      "0.9710 (+/-0.0117) for {'C': 2.5}\n",
      "\n",
      "### Tuning hyper-parameters for severe_toxic ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 0.6}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9847 (+/-0.0170) for {'C': 0.1}\n",
      "0.9853 (+/-0.0164) for {'C': 0.2}\n",
      "0.9856 (+/-0.0161) for {'C': 0.3}\n",
      "0.9858 (+/-0.0162) for {'C': 0.4}\n",
      "0.9858 (+/-0.0163) for {'C': 0.5}\n",
      "0.9858 (+/-0.0166) for {'C': 0.6}\n",
      "0.9858 (+/-0.0168) for {'C': 0.7}\n",
      "0.9857 (+/-0.0169) for {'C': 0.8}\n",
      "0.9857 (+/-0.0172) for {'C': 0.9}\n",
      "0.9856 (+/-0.0173) for {'C': 1.0}\n",
      "\n",
      "### Tuning hyper-parameters for obscene ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1.0}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9849 (+/-0.0132) for {'C': 0.6}\n",
      "0.9850 (+/-0.0130) for {'C': 0.7}\n",
      "0.9851 (+/-0.0128) for {'C': 0.8}\n",
      "0.9852 (+/-0.0127) for {'C': 0.9}\n",
      "0.9852 (+/-0.0126) for {'C': 1.0}\n",
      "0.9852 (+/-0.0126) for {'C': 1.1}\n",
      "0.9852 (+/-0.0125) for {'C': 1.2}\n",
      "0.9852 (+/-0.0125) for {'C': 1.3}\n",
      "0.9851 (+/-0.0125) for {'C': 1.4}\n",
      "0.9851 (+/-0.0125) for {'C': 1.5}\n",
      "\n",
      "### Tuning hyper-parameters for threat ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1.8}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9845 (+/-0.0367) for {'C': 1.1}\n",
      "0.9846 (+/-0.0367) for {'C': 1.2}\n",
      "0.9847 (+/-0.0368) for {'C': 1.3}\n",
      "0.9847 (+/-0.0368) for {'C': 1.4}\n",
      "0.9848 (+/-0.0369) for {'C': 1.5}\n",
      "0.9848 (+/-0.0370) for {'C': 1.6}\n",
      "0.9849 (+/-0.0371) for {'C': 1.7}\n",
      "0.9849 (+/-0.0373) for {'C': 1.8}\n",
      "0.9849 (+/-0.0375) for {'C': 1.9}\n",
      "0.9849 (+/-0.0377) for {'C': 2.0}\n",
      "0.9849 (+/-0.0379) for {'C': 2.1}\n",
      "0.9848 (+/-0.0382) for {'C': 2.2}\n",
      "0.9848 (+/-0.0384) for {'C': 2.3}\n",
      "0.9848 (+/-0.0385) for {'C': 2.4}\n",
      "0.9848 (+/-0.0388) for {'C': 2.5}\n",
      "\n",
      "### Tuning hyper-parameters for insult ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 0.9}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9765 (+/-0.0135) for {'C': 0.6}\n",
      "0.9767 (+/-0.0134) for {'C': 0.7}\n",
      "0.9767 (+/-0.0133) for {'C': 0.8}\n",
      "0.9767 (+/-0.0133) for {'C': 0.9}\n",
      "0.9767 (+/-0.0132) for {'C': 1.0}\n",
      "0.9767 (+/-0.0132) for {'C': 1.1}\n",
      "0.9767 (+/-0.0132) for {'C': 1.2}\n",
      "0.9766 (+/-0.0132) for {'C': 1.3}\n",
      "0.9766 (+/-0.0132) for {'C': 1.4}\n",
      "0.9765 (+/-0.0132) for {'C': 1.5}\n",
      "\n",
      "### Tuning hyper-parameters for identity_hate ###\n",
      "\n",
      "Best hyper-parameters on development set:\n",
      "{'C': 1.0}\n",
      "\n",
      "Grid search scores on development set:\n",
      "0.9766 (+/-0.0356) for {'C': 0.6}\n",
      "0.9768 (+/-0.0355) for {'C': 0.7}\n",
      "0.9769 (+/-0.0355) for {'C': 0.8}\n",
      "0.9769 (+/-0.0355) for {'C': 0.9}\n",
      "0.9770 (+/-0.0355) for {'C': 1.0}\n",
      "0.9770 (+/-0.0356) for {'C': 1.1}\n",
      "0.9770 (+/-0.0356) for {'C': 1.2}\n",
      "0.9769 (+/-0.0356) for {'C': 1.3}\n",
      "0.9769 (+/-0.0358) for {'C': 1.4}\n",
      "0.9769 (+/-0.0358) for {'C': 1.5}\n",
      "\n",
      "Wall time: 5h 42min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Tune C for each category CV=100 \n",
    "parameters_dic={'toxic':{'C':[1.1,1.2,1.3,1.4,1.5, 1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5]},\n",
    "                'severe_toxic':{'C':[.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0]},\n",
    "                'obscene':{'C':[.6,.7,.8,.9,1.0,1.1,1.2,1.3,1.4,1.5]},\n",
    "                'threat':{'C':[1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5]}, \n",
    "                'insult':{'C':[.6,.7,.8,.9,1.0,1.1,1.2,1.3,1.4,1.5]}, \n",
    "                'identity_hate':{'C':[.6,.7,.8,.9,1.0,1.1,1.2,1.3,1.4,1.5]}}\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    parameters = parameters_dic[category]\n",
    "    log_reg = LogisticRegression(solver='sag')   \n",
    "    clf= GridSearchCV(log_reg, parameters, scoring='roc_auc', cv=100)\n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    print_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below was run to check the performance with the best parameters more easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean CV score on dev. set for toxic is 0.9709\n",
      "Mean CV score on dev. set for severe_toxic is 0.9857\n",
      "Mean CV score on dev. set for obscene is 0.9851\n",
      "Mean CV score on dev. set for threat is 0.9845\n",
      "Mean CV score on dev. set for insult is 0.9764\n",
      "Mean CV score on dev. set for identity_hate is 0.9765\n",
      "\n",
      "Mean CV score on dev. set for All categories is 0.9799\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_C = {'toxic':1.4,'severe_toxic':.6,'obscene':1.0,\n",
    "        'threat':1.8, 'insult':0.9, 'identity_hate':1.0}\n",
    "score_all = []\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    log_reg = LogisticRegression(solver='sag')   \n",
    "    clf= GridSearchCV(log_reg, {'C':[best_C[category]]}, scoring='roc_auc', cv=10)\n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    print(\"Mean CV score on dev. set for %s is %0.4f\" %(category,clf.best_score_))\n",
    "    score_all.append(clf.best_score_)\n",
    "print()\n",
    "print(\"Mean CV score on dev. set for All categories is %0.4f\" %np.mean(score_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id']=test['id']\n",
    "\n",
    "best_C = {'toxic':1.4,'severe_toxic':.6,'obscene':1.0,\n",
    "        'threat':1.8, 'insult':0.9, 'identity_hate':1.0}\n",
    "for category in categories:\n",
    "    train_labels = train[category]\n",
    "    clf = LogisticRegression(solver='sag', C=best_C[category])   \n",
    "    clf.fit(train_feature_matrix, train_labels)\n",
    "    submission[category] = clf.predict_proba(test_feature_matrix)[:,1] #second column!!\n",
    "    \n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found AUC on the test set is .9745 on the leaderboard (not bad comparing to the score on the development set .9799). This is slightly worse than the last test score I got without cleaning and stemming (.9756) although the score on the development set was slightly better with stemming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'Section8'></a>\n",
    "## 8. Summary so far\n",
    "\n",
    "#### Data\n",
    "- From a Kaggle Competition (by Jigsaw and Google)\n",
    "- Wikipedia comments labeled by human raters for toxic behavior\n",
    "- 6 types of toxicity (toxic, severe toxic, obscene, threat, insult, identity_hate)\n",
    "\n",
    "#### Goal of this project\n",
    "Create a model that predicts a probability of each type of toxicity for each comment\n",
    "\n",
    "#### Brief EDA\n",
    "- 159,571 training comments each with id and 6 types of toxicity labels\n",
    "- 153,164 test comments with id\n",
    "- Proportion for each type of toxicity (very unbalanced!!)\n",
    "  - Toxic         9.6 % \n",
    "  - Severe Toxic  1.0 %\n",
    "  - Obcene        5.5 %\n",
    "  - Threat        0.3 %\n",
    "  - Insult        4.9 %\n",
    "  - Identity_hate 0.9 %\n",
    "- Comment length from 6 to 5000 characters\n",
    "- No missing values\n",
    "\n",
    "#### Cleaning and Stemming \n",
    "- Steps for each doument:\n",
    "  - Remove punctuations \n",
    "  - Split each document to make a word list\n",
    "  - Stemming using SnowballStemmer(\"english\")\n",
    "  - Combine stemmed words back together\n",
    "- Used apply() function to apply the above steps to all documents\n",
    "\n",
    "#### TfidfVectorizer \n",
    "- __Vectorizer:__ convert a collection of text documents into a numerical matrix with 1 row per document and 1 column per token (e.g. word) by tokenizing, counting, normalizing\n",
    "\n",
    "- __Tf-idf__ (term frequency inverse document frequency) weighting: frequency of a term in a given document multiplied by log((1+#documents)/(1+__#documents containing the term__)) + 1\n",
    "\n",
    "- __Hyper-parameters:__\n",
    "  - analyzer: {'word','char'}\n",
    "  - stop_words: None, string {'english'}, or list \n",
    "  - sublinear_tf: boolean for applying sublinear tf  scaling (replace tf with 1+log(tf) )\n",
    "  - token_pattern: regular expression denoting what constitutes a token e.g. r'\\w{1,}' for 1+ char words\n",
    "  - ngram_range: (min_n, max_n) e.g. (1,1), (1,2)\n",
    "  - max_features: build a vocabulary that only consider the top max_features ordered by tf across the corpus\n",
    "\n",
    "- __Tuned hyper-parameters for vectorizer:__\n",
    "  - token_pattern: 1+ and 2+ char words\n",
    "  - ngram_range: (1,1) and (1,2) \n",
    "\n",
    "- I used both train and test sets to fit the vectorizer and transfrom the sets separately.\n",
    "\n",
    "#### Logistic Regression \n",
    "- __Hyper-parameters tuned:__\n",
    "  - solver: 'liblinear' (default) vs. 'sag' (uses a Stochastic Average Gradient descent. faster than other solvers for large datasets). I found 'sag' is slightly better.\n",
    "  - C: Inverse of regularization strength (I used \"coarse to fine\" strategy) I found the best C value for each type of toxicity.\n",
    "\n",
    "- __GridSearchCV__ was for tuning, cross validation and stratified split. The split made training and developement sets from the given training set. The test set was given separately from Kaggle and was tested on the leaderboard. \n",
    "- __scoring:__ __'roc_auc'__ is used in the Kaggle competition, but AUC is not ideal for unbalanced classes. \n",
    " - __Average AUC on dev. set: .9799__ \n",
    "   - The best C is between .6 to 1.8 (different for each type of toxicity). \n",
    "   - The test set tested on the leaderboard gave a similar AUC score (.9745).\n",
    "   - C is higher for more unbalanced types of toxicity; less regularization is required for more unbalanced type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'Section9'></a>\n",
    "## 9.  Future directions\n",
    "\n",
    "- More algorithms and models will be tested. I hope to try Recurrent Neural Networks (RNN) such as LSTM and some ensemble methods.\n",
    "- Feature engineering can be done.\n",
    "- I want to try performance measures other than AUC since the data is unbalanced. If I use another metric, I will not be able to utilize the test set which can be evaluated only by AUC on the Kaggle leaderboard.\n",
    "- I will invesitigate feature importances (if available from some classifiers such as Random Forest) and words with high tf-idf for each category.\n",
    "- It might be fun to see some graphs of words with top tf-idf or top feature importances for each type of toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
